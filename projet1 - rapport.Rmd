---
title: "Seeds - Random effect logistic regression"
author: "BRUNO LOPES Matheus, MOURDI Elias, SELAMNIA Najib, TRIOMPHE Amaury"
date: "15/04/2024"
output:
  html_document:
    df_print: paged
keep_tex: yes
---

**Lien vers notre Github** : `https://github.com/azer1230/-BAYES-Projet-1`

# Données étudiées

Le contexte de notre projet est l'étude de la germination de graines respectant certaines propriétés. Dans notre exemple, $N = 21$ plaques sont disposées pour accueillir 2 types de graines issues de 2 types de racines. Les tableaux ci-dessous recensent les résultat pour ces 4 types de population. $\forall i \in \{1,...,21\}, r_i$ correspond au nombre de graines germées et $n_i$ correspond au nombre total de graines sur la $i-$ème plaque. Le rapport entre ces deux grandeurs est donc la proportion de graines ayant germé sur la dite plaque.

```{=tex}
\begin{table}[h]
\centering
\small
\begin{minipage}{0.45\textwidth}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{Bean}} & \multicolumn{3}{|c|}{\textbf{Cucumber}} \\
\hline
\textbf{r} & \textbf{n} & \textbf{r/n} & \textbf{r} & \textbf{n} & \textbf{r/n} \\
\hline
10 & 39 & 0.26 & 5 & 6 & 0.83 \\
23 & 62 & 0.37 & 53 & 74 & 0.72 \\
23 & 81 & 0.28 & 55 & 72 & 0.76 \\
26 & 51 & 0.51 & 32 & 51 & 0.63 \\
17 & 39 & 0.44 & 46 & 79 & 0.58 \\
 & & & 10 & 13 & 0.77 \\
\hline
\end{tabular}
\caption{Données récupérées pour la graine seed O. aegyptiaco 75}
\label{tab:tableau1}
\end{minipage}\hfill
\begin{minipage}{0.45\textwidth}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{Bean}} & \multicolumn{3}{|c|}{\textbf{Cucumber}} \\
\hline
\textbf{r} & \textbf{n} & \textbf{r/n} & \textbf{r} & \textbf{n} & \textbf{r/n} \\
\hline
8 & 16 & 0.5 & 3 & 12 & 0.25 \\
10 & 30 & 0.33 & 22 & 41 & 0.54 \\
8 & 28 & 0.29 & 15 & 30 & 0.5 \\
23 & 45 & 0.51 & 32 & 51 & 0.63 \\
0 & 4 & 0 & 3 & 7 & 0.43 \\
\hline
\end{tabular}
\caption{Données récupérées pour la graine seed O. aegyptiaco 73}
\label{tab:tableau2}
\end{minipage}
\end{table}
```
# Cadre mathématique

## Hypothèses sur nos données (Matheus)

Si $p_i$ est la probabilité de germination sur la plaque $i$, alors supposons que le nombre de graines germées $r_i$ suit une loi binomiale :

$$
r_i \sim \text{Binomial}(p_i,n_i)
$$

De plus, supposons que le modèle est essentiellement une régression logistique à effets aléatoires, ce qui permet de traiter la surdispersion. Autrement dit :

$$
  \text{logit}(p_i) = \alpha_0 + \alpha_1x_{1i} + \alpha_2x_{2i} + \alpha_{12}x_{1i}x_{2i} + b_i \\
  \text{où } b_i \sim \mathcal{N}(0,\frac{1}{\tau})
$$

Où $x_{1i}$, $x_{2i}$ sont le type de graine et l'extrait de racine de la $i$-ème plaque, et un terme d'interaction $\alpha_{12}x_{1i}x_{2i}$ est inclus. $\alpha_0, \alpha_1, \alpha_2, \alpha_{12}, \tau$ ont des priors indépendants "non informatifs" fournis, qui seront supposés comme suit :

$$
  \alpha_i \sim \mathcal{N}(0, 10^6), \: \text{pour} \: i \in \{0, 1, 2\} \\
  \alpha_{12} \sim \mathcal{N}(0, 10^6) \\
  \tau \sim \text{gamma}(10^{-3}, 10^{-3})
$$

Une dernière hypothèse que nous ferons également est que $r_i$ sont indépendants.

## Graphe acyclique orienté (Najib)

## Lois conditionnelles (Matheus)

Comme nous allons appliquer Hastings-within-Gibbs, nous devrons avoir les lois conditionnelles de tous les paramètres de l'expression de $logit(p_i)$, c'est-à-dire que nous devrons obtenir toutes les lois postérieures. Pour $\alpha_0$, nous aurons :

$$
  \pi(\alpha_0|\alpha_1, \alpha_{12}, \alpha_2, r, b, \tau) \propto \pi(\alpha_1, \alpha_{12}, \alpha_2, r, b, \tau|\alpha_0)\pi(\alpha_0)
$$

Dans le contexte de H-W-Gibbs, comme nous allons mettre à jour les paramètres séparément en considérant les autres comme des valeurs fixes, nous aurons :

$$
    \pi(\alpha_0|\alpha_1, \alpha_{12}, \alpha_2, r, b, \tau) \propto \pi(r|\alpha_0,\alpha_1, \alpha_{12}, \alpha_2, b, \tau)\pi(\alpha_0)\\ =  \pi(\alpha_0)\prod_{i=1}^N\pi(r_i|\alpha_0,\alpha_1, \alpha_{12}, \alpha_2, i,b, \tau)\\ = \pi(\alpha_0)\prod_{i=1}^Np_i^{r_i}(1-p)^{n_i - r_i}
$$

Comme tous suivent la même loi a priori, nous aurons des expressions similaires pour $\alpha_1, \alpha_{12}$ et $\alpha_2$. Pour $\tau$, nous devrons, comme $\tau$ dépend de $b$ qui suit une loi normale, qui dans ce cas est conjuguée par la loi gamma (loi a priori de $\tau$), obtenir directement la loi a posteriori de $\tau$ :

$$
  \tau|\alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i , b, r \sim gamma(10^{-3} + \frac{N}{2}, 10^{-3} + \frac{\sum_{i=1}^Nb_i^2}{2})
$$

Une fois $\tau$ mis à jour dans l'algorithme, nous pourrons mettre à jour chaque $b_i$, pour $i \in \{1, ..., N\}$, où chacun aura la loi a posteriori suivante :

$$
  \pi(b_i| \alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i , r_i, \tau) \propto \pi( \alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i , r_i, \tau| b_i)\pi(b_i)
$$

En considérant que $\alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i, \tau$ sont des paramètres déjà fixes et que $b_i \sim N(0,\frac{1}{\tau})$, nous pouvons écrire :

$$
  \pi(b_i| \alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i , r_i, \tau) \propto \pi(r_i|\alpha_0, \alpha_{1}, \alpha_{12},\alpha_2, i , \tau, b_i)\exp(-\frac{b_i^2\tau}{2}) \\
  =p_i^{r_i}(1-p_i)^{n_i-r_i}\exp{(-\frac{b_i^2\tau}{2})}
$$

Maintenant, ayant toutes les lois conditionnelles, nous pouvons appliquer notre algorithme Hastings-within-Gibbs.

# Résultats de l'implémentation algorithmique

Grâce au calcul précédent des lois conditionnelles, nous avons pu implémenter un algorithme de Hasting Within Gibbs pour estimer nos paramètres. De la même manière que ce qui est donné dans l'énoncé, nous avons généré $10^4$ réalisations auxquelles nous avons retiré les 1000 premières, correspondant à la burnin period. Les résultats obtenus, ainsi qu'une comparaison avec ce qui est donné dans l'énoncé, sont mentionnés dans le tableau ci-dessous.

```{=tex}
\begin{table}[h]
\centering
\small
\begin{minipage}{0.45\textwidth}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{2}{|c|}{\textbf{Moyenne}} & \multicolumn{2}{|c|}{\textbf{Écart-type}} \\
\hline
\textbf{Paramètres} & \textbf{Résultat} & \textbf{Énoncé} & \textbf{Résultat} & \textbf{Énoncé} \\
\hline
$\alpha_0$ & -0.5562 & -0.5525 & 0.1865 & 0.1852 \\
$\alpha_1$ & 0.0706 & 0.08382 & 0.3252 & 0.3031 \\
$\alpha_{12}$ & -0.8021 & -0.8165 & 0.4564 & 0.4109 \\
$\alpha_2$ & 1.3511 & 1.346 & 0.2745 & 0.2564 \\
$\sigma$ & 0.3198 & 0.267 & 0.0661 & 0.1471 \\
\hline
\end{tabular}
\caption{Résultats de notre algorithme Hastings within Gibbs}
\end{minipage}
\end{table}
```
On rend également compte des résultats des chaînes de Markov générées (à gauche), ainsi que de leurs distributions (à droite) dans ls graphiques ci-dessous:

```{r, echo=FALSE, fig.align='center'}
# Notations changées par rapport au fichier seeds.data pour être en accord avec 
# la consigne donnée
"N" <- 21 
"r" <- c(10, 23, 23, 26, 17, 5, 53, 55, 32, 46, 10, 8, 10, 8, 23, 0, 3, 22, 15, 32, 3)
"n" <- c(39, 62, 81, 51, 39, 6, 74, 72, 51, 79, 13, 16, 30, 28, 45, 4, 12, 41, 30, 51, 7)
"x1" <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
"x2" <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1)

alpha0 <- 0
alpha1 <- 0
alpha2 <- 0
alpha12 <- 0
tau <- 10
b <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

seeds = function(nchain, N, r, n, x1, x2, alpha0, alpha1, alpha2, alpha12, tau, b, prop_sd){
  
  # Initialisation
  res = matrix(NA, nchain + 1, 5)
  res[1, ] = c(alpha0, alpha1, alpha12, alpha2, 1/sqrt(tau)) # le dernier terme vaut sigma

  p = plogis(alpha0 + alpha1 * x1 + alpha2 * x2 + alpha12 * x1 * x2 + b)
  
  res_b = matrix(NA, nchain + 1, N)
  res_b[1, ] = b
  
  acc_rates = rep(0, 4) # pour les 4 alpha
  
  for (i in 1:nchain){
    
    # Mise à jour de alpha0
    alpha0 = res[i, 1]
    prop = rnorm(1, alpha0, prop_sd[1]) # marche aléatoire simple
    prop_p = plogis(prop + alpha1 * x1 + alpha2 * x2 + alpha12 * x1 * x2 + b)
    
    top = - ((prop^2) / (2 * 1e6)) + sum(r * log(prop_p)) + sum((n-r) * log(1 - prop_p))
    bottom = - ((alpha0^2) / (2 * 1e6)) + sum(r * log(p)) + sum((n-r) * log(1 - p))
    acc_prob = exp(top - bottom) # Ratio des noyaux vaut 1 (symétrie du noyau)
    
    if (runif(1) < min(1, acc_prob)){
      alpha0 = prop
      p = prop_p
      acc_rates[1] = acc_rates[1] + 1
    }
    
    # Mise à jour de alpha1
    alpha1 = res[i, 2]
    prop = rnorm(1, alpha1, prop_sd[2]) # marche aléatoire simple
    prop_p = plogis(alpha0 + prop * x1 + alpha2 * x2 + alpha12 * x1 * x2 + b)
    
    top = - ((prop^2) / (2 * 1e6)) + sum(r * log(prop_p)) + sum((n-r) * log(1 - prop_p))
    bottom = - ((alpha1^2) / (2 * 1e6)) + sum(r * log(p)) + sum((n-r) * log(1 - p))
    acc_prob = exp(top - bottom) # Ratio des noyaux vaut 1 (symétrie du noyau)
    
    if (runif(1) < min(1, acc_prob)){
      alpha1 = prop
      p = prop_p
      acc_rates[2] = acc_rates[2] + 1
    }

    # Mise à jour de alpha12
    alpha12 = res[i, 3]
    prop = rnorm(1, alpha12, prop_sd[3]) # marche aléatoire simple
    prop_p = plogis(alpha0 + alpha1 * x1 + alpha2 * x2 + prop * x1 * x2 + b)
    
    top = - ((prop^2) / (2 * 1e6)) + sum(r * log(prop_p)) + sum((n-r) * log(1 - prop_p))
    bottom = - ((alpha12^2) / (2 * 1e6)) + sum(r * log(p)) + sum((n-r) * log(1 - p))
    acc_prob = exp(top - bottom) # Ratio des noyaux vaut 1 (symétrie du noyau)
    
    if (runif(1) < min(1, acc_prob)){
      alpha12 = prop
      p = prop_p
      acc_rates[3] = acc_rates[3] + 1
    }
    
    # Mise à jour de alpha2
    alpha2 = res[i, 4]
    prop = rnorm(1, alpha2, prop_sd[4]) # marche aléatoire simple
    prop_p = plogis(alpha0 + alpha1 * x1 + prop * x2 + alpha12 * x1 * x2 + b)
    
    top = - ((prop^2) / (2 * 1e6)) + sum(r * log(prop_p)) + sum((n-r) * log(1 - prop_p))
    bottom = - ((alpha2^2) / (2 * 1e6)) + sum(r * log(p)) + sum((n-r) * log(1 - p))
    acc_prob = exp(top - bottom) # Ratio des noyaux vaut 1 (symétrie du noyau)
    
    if (runif(1) < min(1, acc_prob)){
      alpha2 = prop
      p = prop_p
      acc_rates[4] = acc_rates[4] + 1
    }
    
    # Mise à jour de tau
    tau = rgamma(1, shape = 10e-3 + N / 2, scale = 1e-3 + 0.5 * sum(b^2))

    # Mise à jour de b
    for (j in 1:N){
      prop = rnorm(1, b[j], prop_sd[5])
      prop_p_j = plogis(alpha0 + alpha1 * x1[j] + alpha2 * x2[j] + alpha12 * x1[j] * x2[j] + prop)
      
      top = - (prop^2 * tau / 2) + r[j] * log(prop_p_j) + (n[j] - r[j]) * log(1 - prop_p_j)
      bottom = - (b[j]^2 * tau / 2) + r[j] * log(p[j]) + (n[j] - r[j]) * log(1 - p[j])
      acc_prob = exp(top - bottom)
      
      if (runif(1) < min(1, acc_prob)){
        b[j] = prop
        p[j] = prop_p_j
      }
    }
    
    # Mise à jour de la chaine de Markov et de b
    res[i+1, ] = c(alpha0, alpha1, alpha12, alpha2, 1/sqrt(tau))
    res_b[i+1, ] = b
  }
  
  my_list <- list("chain" = res, "b_chain" = res_b, "acc_rates" = acc_rates)
  return(my_list)
}

resultat = seeds(1e4, N, r, n, x1, x2, alpha0, alpha1, alpha2, alpha12, tau, b, prop_sd = c(0.3, 0.3, 0.3, 0.3, 0.3)) # prop_sd choisi pour avoir une allure de chaîne cohérente

resultat_chain = resultat$chain[1001:nrow(resultat$chain), ] # on enlève les 1000 premiers (burnin)

moychain = colMeans(resultat_chain) # moyenne
sdchain = apply(resultat_chain, 2, sd) # écart type


library(coda)
par(ask = FALSE, mfrow = c(3, 1), mar = c(1, 1, 3, 3)) # Configure la disposition des graphiques 

# Tracer les 3 premiers graphiques des chaînes de Markov
plot(mcmc(resultat_chain[,1:3]))

mtext(expression("Graphiques pour " * alpha[0]), side = 3, line = 23)
mtext(expression("Graphiques pour " * alpha[1]), side = 3, line = 11.5)
mtext(expression("Graphiques pour " * alpha[12]), side = 3, line = 0.5)

par(mfrow = c(2, 1)) # Configure la disposition des graphiques 

# Tracer les 2 derniers graphiques des chaînes de Markov
plot(mcmc(resultat_chain)[,4:5])

mtext(expression("Graphiques pour " * alpha[2]), side = 3, line = 12)
mtext(expression("Graphiques pour " * sigma), side = 3, line = 1)
```

Les résultats obtenues sont cohérents avec l'objectif initial visé dans l'énoncé. Les valeurs sont distribuées autour des moyennes attendues et les écart-types sont également en accord avec les attentes, en observant des variations inférieurs à 20%.

(Voir pour les sigma)

# Analyse des résultats (?)
